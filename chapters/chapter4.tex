
\chapter{多個語音離散表徵與音位的關係}

\textcolor{red}{tokenization 的翻譯需要調整！}

\section{動機}

　　如前一章所述，一個文字或音位往往對應到上百毫秒的語音訊號，然而單一離散單元所對應的聲音訊號為 10 或 20 毫秒，亦即同一段語音所對應的離散單元數目將比音位或文字多出許多。本章節從自然語言處理中獲取靈感，將分詞演算法（Tokenization）應用於離散單元序列上，並應用上一章節的分析方法檢驗將多個離散單元所組成之符記。探討分詞後，離散單元是否可以同時擁有無文字（Textless）\cite{lakhotia_generative_2021, lakhotia_generative_2021-1, noauthor_textless_2021} 的特性，且更接近音位的序列，成為更好的語音表徵。

\section{相關研究} 

　　在無文字架構被提出後的約兩年後，藉分詞方法組合離散單元的研究逐步出現。最初提出「聲學片段（Acoustic Piece）」的是任氏（Ren）等人 \cite{ren_speech_2022}\citetag{1-22A4-Pretrain-ap}），該論文比對離散單元序列及對應的文字轉寫，從中觀察到許多相似的模式（Pattern），而且不限於單一語者。受此啟發，本論文首先將離散單元使用句子片段（SentencePiece） \cite{kudo_sentencepiece_2018} 分詞，獲得新的符記 --- 「聲學片段（Acoustic Piece）」，並用於語音辨識的預訓練上。

        不久，由吳氏（Wu）提出的 Wav2seq \cite{wu_wav2seq_2023}\citetag{2-22A5-wav2seq}論文中，考量文字與語音的序列長度差異，並基於離散單元和音位的關聯性，將離散單元視為字符（Character），嘗試將這些字符透過分詞方法組成「虛擬語言（Pseudo-language\footnote{偽語言對應之離散單元被視為「虛擬文字（Pseudo-text）」}）」，來幫助語音到文字的模型。因為解碼器在實際應用時需要生成的序列多是文字的符記 --- 次詞單位（Subword Unit），因此該篇研究旨在讓模型在預訓練後可以快速適應下游任務。與前一篇呼應，「聲學片段」對語音預訓練的效果在\cite{10096788}\citetag{3-23A-coarser-grain}中被探討，此後聲學片段更被應用於縮短資料序列長度\cite{chang_exploration_2023}\citetag{4-23B-Exploration of Efficient End-to-End ASR using Discretized Input from Self-Supervised Learning} 、語音生成\cite{shen2024acoustic}\citetag{5-24A-speech-gen}，或學習更穩健（Robust）的語音表徵\cite{chang2023r}\citetag{6-23B-rspin-acousticpiece}。

        近期，張氏（Chang）等人\cite{chang_exploring_2024}\citetag{7-23B-shinji-hsiuhsuan}將以分詞方法處理離散單元的流程（Pipeline）納入 ESPNet 套件 \cite{watanabe2018espnet} 中，並在語音辨識、語音翻譯等任務中獲得了超越以往的表現，進一步證明了這個方法的效果。

\section{分詞方法}

　　在以文字為主體的自然語言處理中，文字文本除了以單詞（Word）或字元（Character）為處理單位，更常見的作法是透過分詞演算法（Tokenization）將文本分段，以「次詞單位（Subword Unit）」構成詞彙表來重新編碼文本，用於文字模型的訓練與推理。

        分詞方法的優點一般包含：

\begin{enumerate}
    \item 固定詞彙表大小，避免未登錄詞（Out-of-vocabulary，OOV）
    \item 縮短資料序列的長度，提升訓練和推論的效率。
    \item 分解單詞，捕捉更細緻的語意關係，模擬如英語中的字首（Prefix）、字尾（Suffix）等等具有特定意義的文字組合。
\end{enumerate}

\subsection{常見演算法}

　　以下介紹幾種常見的分詞方法：

\paragraph{位元組對編碼（Byte Pair Encoding，BPE）}\hfill \break

　　位元組對編碼 \cite{10.5555/177910.177914, sennrich_neural_2016} 是一種常用的分詞方法，最初來自資料壓縮技術 \cite{10.5555/177910.177914}，後來被引入到自然語言處理領域，用以處理機器翻譯問題 \cite{sennrich_neural_2016} 。
該演算法從字元開始，根據詞彙表中各個次詞單位的頻率，反覆合併常見的字元成為新的次詞單位，直到達到預定的詞彙表大小。

\paragraph{單詞片段（WordPiece）}\hfill \break

　　WordPiece \cite{wu2016google} 演算法由 Google 用以訓練機器翻譯系統，並在 BERT \cite{devlin_bert_2019} 模型中被使用而廣為人知。與 BPE 同樣是透過反覆合併的策略，但合併的依據改以機率模型取代出現頻率。

\paragraph{單一詞語言模型（Unigram Language Model）}\hfill \break

　　單一詞語言模型 \cite{kudo2018subword} 是基於語言模型的分詞方法，以機率分佈選擇次詞單位，並以最大化輸入文本的機率來為文本分段。

\subsection{句子片段（SentencePiece）套件}

　　SentencePiece \cite{kudo_sentencepiece_2018}
是由 Google 開發的分詞套件，實作了前述的 BPE 和單一詞演算法。其優勢在於可應用於不同語言，尤其用於處理中文、日文等不使用空格分隔單詞的語言文本時，此套件大大的簡化了前處理的流程。

\section{衡量方式}

　　本章節沿用上一章節 LibriSpeech 資料集的 train-clean-100 訓練子集，以及相同的分析數據以進行比對。由於與上一章節的差異僅在分詞方法的引入，因此數據結果將多紀錄分詞前後序列長度的變化；其他操控變因包含分詞方法與詞表大小。考慮到語音訊號本身不如英語等文字，在書寫時就已經具備空格分隔單詞，因此以下分析結果皆採用 SentencePiece 套件中實作之單一詞演算法為分詞方法，並比較詞表大小 500、1000、8000、10000、20000 五種設定的結果差異。（空間不足時則僅呈現 500、1000、10000 三種設定的趨勢。）

\section{分析結果}\newcommand{\jefftablesep}{\vspace{0.5cm}}\renewcommand{\arraystretch}{0.7} % 調整行高

    以下數據中的「長度壓縮比率」係指透過分詞方法後，每一個句子的「單詞」數與原先離散單元的數量相比之比值。由於長度壓縮比率是針對離散單元分詞所得到，與標註無關，因此只在音位分析的表格上呈現。

\subsection{基於各自音位的分析}

　　首先，為了比較不同詞表大小對於純度、相互資訊等數據的影響，先分別固定語音模型為 HuBERT 和 Wav2vec 2.0，在離散單元的分群數量為 50、100、200 三種設定下，觀察詞表大小造成的變化。由 HuBERT （表 \ref{tab:hubert-phn-results}）和 Wav2vec 2.0（表 \ref{tab:w2v2-phn-results}）的數據比較可觀察到，詞表大小上升除了使得音位純度提高以外，相互資訊也是隨之提高的，可以發現使用分詞方法並給予足夠大的詞表，對於找出語音中的資訊確實有所幫助。

        接著從另一個角度切入，比較同樣都是離散單元分群數為 200 的條件下，不同語音基石模型的分析數據。由表 \ref{tab:ch4-models-phn} 可以發現，HuBERT 模型在音位純度與相互資訊勝過其他模型，這個結論與上一章節是一致的。

        有趣的是，觀察長度壓縮比率可以發現，CPC 模型在分詞演算法的引入後，能夠使序列變得最短，但同時在音位純度與相互資訊上也有所犧牲；而 HuBERT 雖然在這些分析數據上高過其他三者，卻同時達成了比 Wav2vec 2.0 和 LogMel 更好的壓縮比率。因此綜合看來，或許這是為什麼目前使用語音離散單元進行研究時，HuBERT 模型仍然是領域內的首選。

                \input{tables/chapter4/tab1}

\subsection{基於語音學分類的分析}

　　最後觀察將語音標註換成語音學分類的結果，一樣可以從表 \ref{tab:hubert-pcls-results}、\ref{tab:w2v2-pcls-results} 和 \ref{tab:ch4-models-pcls} 觀察到與上一小節相同的趨勢。

                \input{tables/chapter4/tab2}

\section{本章總結}

　　藉由分詞演算法的引入，我們可以發現在序列長度相對縮短的前提下，音位的純度卻也獲得了提升，足以證明分詞演算法的引入，可以幫助離散單元考量多於一個音框的語音資訊，建構於精細的音框之上，找出更接近人類解讀語音最小單位資訊。期望以此發現，可以使得語音語言模型建立時，模型在處理語音語料庫時，能夠以更接近文字的序列長度與資訊進行訓練，獲得更接近文字模型的效果。

\section{實驗集與分析模型}

　　本研究的分析對象參考無文字架構 \cite{noauthor_textless_2021, lakhotia_generative_2021, lakhotia_generative_2021-1} 的研究，
採用論文中提及的四種語音表徵，簡述如下：

\begin{itemize}
    \item CPC：卷積式編碼器 + 遞迴式預測器，以對比式學習訓練。表徵來自預測器的中間層，每 10 毫秒提取一個向量表徵作為音框
    \item Wav2vec 2.0：卷積式編碼器 + 轉換器預測器，以對比式學習訓練。表徵來自轉換器第 14 層，每 20 毫秒作為一個音框
    \item HuBERT：卷積式編碼器 + 轉換器預測器，以預測式學習訓練，其訓練目標為 K-平均分群演算法的結果，透過遮蔽語言模型的方式訓練。表徵來自轉換器第 6 層，每 20 毫秒作為一個音框
    \item LogMel：為 80 維對數梅爾時頻譜的聲學特徵，在此作為比較基線（Baseline）。音框寬度為 10 毫秒
\end{itemize}

        我們使用該論文釋出之預訓練模型與 K-平均量化模型。預訓練模型細節詳述於 \cite{lakhotia_generative_2021-1} 中，量化模型則是該篇論文透過公開的 LibriSpeech 資料集 \cite{panayotov_librispeech_2015} 中 train-clean-100 訓練集，獲取語音表徵後執行 K-平均分群演算法所得，並釋出群數為 50、100 和 200 的三個版本。

        本論文亦以 LibriSpeech train-clean-100 作為分析對象，將語音語料庫的語音資料經過四個模型獲取連續表徵後，再經過量化模型得到完全由離散單元組成的「偽文字」語料。

        針對語音學的音位標註，透過強迫對齊器（Forced-aligner）\footnote{https://github.com/MontrealCorpusTools/Montreal­Forced­Aligner}的英語預訓練模型，從語料庫的文字轉寫取得語音資料的音位標註與對應的時間範圍。最後透過語音表徵各自的時間解析度生成以音框為單位的音位標註語料。最後將兩者對語音資料集進行音位標註相關性的分析。

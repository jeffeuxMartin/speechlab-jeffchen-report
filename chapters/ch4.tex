
\chapter{多個語音離散單元}   \input{chapters_stable/tinys}

    {  \jeffcomment{bef analysis} 
{  \jeffcomment{pre}   
\section{動機}            　　本章嘗試分詞法。
\section{相關研究} 　　像 Wav2seq \cite{wu_wav2seq_2023}  等是相關研究。
\section{分詞方法} 　　這邊講述 BPE、Unigram 等演算法具體怎麼實行。}
\section{衡量方式}
　　本章節沿用上一章節 LibriSpeech 資料集的 train-clean-100 訓練子集，以及相同的分析數據以進行比對。由於與上一章節的差異僅在分詞方法的引入，因此數據結果將多紀錄分詞前後序列長度的變化；其他操控變因包含分詞方法與詞表大小。考慮到語音訊號本身不如英語等文字，在書寫時就已經具備空格分隔單詞，因此以下分析結果皆採用 SentencePiece 套件中實作之單一詞演算法為分詞方法，並比較詞表大小 500、1000、8000、10000、20000 五種設定的結果差異。（空間不足時則僅呈現 500、1000、10000 三種設定的趨勢。）  }  % 前面的內容

\section{新。分析結果} 
　　承繼上一個章節的分析方法，我們先對照純度與機率熱圖兩者的對照，並且以語音學排序呈現，觀察聲學片段與音味之間兩者的分佈關係。
\subsection{聲學片段數量的影響}



\mychcnt{3}
\chapter{單一語音離散表徵與音位的關係}

{

　　HuBERT \cite{hsu_hubert_2021, hsu_hubert_2021-2} 和 Wav2vec 2.0 \cite{baevski2020wav2vec} 等語音基石模型的成功，不僅在語音任務上達到了前所未有的表現，還促進了語音表徵離散化的發展。由此產生的「無文字（Textless）」架構 \cite{noauthor_textless_2021, lakhotia_generative_2021, lakhotia_generative_2021-1}，讓人們在處理語音訊號時，有了連續表徵以外的新選擇。離散形式的表徵可以直接應用文字領域發展的技術，如機器翻譯、生成式模型等，為語音技術帶來新的突破。另一方面，基於離散「符記（Token）」的共同形式，離散語音表徵可以更好的整合文字資料，促成多模態領域的發展。跨模態離散表徵的成功，甚至驅使影像領域也開始發展離散表徵，如探討唇語的 AV-HuBERT \cite{shi2021learning} 等等，展現了離散表徵在資料處理上的優勢。

        此外，除了技術的角度切入，這樣的技術也可以探討離散語音表徵成功背後的可能因素，以及它們與語言學對人類語音理解之間的差異，甚至是進一步利用這些技術協助更細緻的探討人類的語音現象。因此，原先在連續語音表徵上的語音學分析，也開始關注離散表徵在多大程度上能描述語音現象，將其列入考量，成為除了連續語音特徵和時頻譜之外的另一個選擇。

\section{相關研究}  

\subsection{無文字與離散語音表徵}

　　自 HuBERT 帶起的研究之後，出現了愈來愈多離散表徵相關的研究\cite{10097097, abdullah23_interspeech, chang_exploration_2023, liu2024dinosr, zhang2024speechtokenizer, huang2023repcodec} 。它們在提出自己的離散表徵時，也會採取 HuBERT 的衡量方式，來驗證這些離散單元與語音中的內容及人類對語音的詮釋之間，具有一定程度的相關性，並從資訊理論（Information Theory）的角度，證明這些離散單元確實具備區分不同語音資訊的能力。

\subsection{語音學分析}

　　由於語音處理本身最終是針對人類語音，因此有一群研究者通過對人類語音的理解，將這些知識應用在分析模型如何對語音訊號建構表徵之上\cite{deseyssel22_interspeech, wells_phonetic_2022, 10097097, abdullah23_interspeech} 。基於這些作品對語音離散表徵的興趣和探討，本論文也先透過過往幾個常用來分析語音表徵的方式，特別是 HuBERT \cite{hsu_hubert_2021-2} 提出的標準進行初步的分析。


\section{衡量指標}

　　本次研究主要探討純度（Purity）、熵（Entropy）和相互資訊（Mutual Information，MI）等指標，這些指標在 HuBERT 中被採用 \cite{hsu_hubert_2021, hsu_hubert_2021-2}，用以比對機器學習過程中得到的虛擬標註與人類標註之間的相關性（Correlation），接下來將詳細解釋這些指標的定義。

        包含聲學特徵與語音基石模型，不論採用何種方式獲得語音表徵，語音訊號皆是以音框（Frame）為基本單位進行處理。具體而言，給予一段聲音訊號，語音處理系統會將這段訊號按照固定時間切割成多個片段分別處理，這些片段的長度被稱之為時間解析度（Time Resolution）。因此，對於任意一段語句（Utterance），系統會將訊號轉換成一連串的向量 $\boldsymbol{x} = [x_1, \cdots\cdots, x_T]$ 作為語音表徵，其中 $T$ 是該段語句的音框總數，與該語句的時長成比例。其中，第 $t$ 個向量 \(x_t\) 表示第 $t$ 個音框的語音訊號內容。在離散表徵的研究中，每個語音表徵向量 $x_t$ 透過向量量化（Vector Quantization）程序，對應到編碼簿中的某個碼字 $e_{z_t}$。因此，該段語句將被表示為 $\boldsymbol{z} = [z_1, \cdots\cdots, z_T]$ 的離散單元序列。

        與此對應，藉由強迫對齊器（Forced-Aligner）或人工標註，可以獲得該段語句的音素標註（Phonetic Label）。然而，通常音素標註是以每個音位的起始至終止的時間點配上此時間段的音位類別呈現。因此，為了配合語音表徵對語句的處理方式，這段音素標註會被依照時間點對應的範圍在音框上對齊，成為 $\boldsymbol{y} = [y_1, \cdots\cdots, y_T]$ 的形式以便分析與後續處理。

        為方便具體說明，吾人從語音常用的 LibriSpeech \cite{panayotov_librispeech_2015} 公開資料集中取一段音檔\footnote{取自 train-clean-100 訓練子集，編號 89-218-0056，即編號 89 語者在章節編號 218 中第 56 句。}，放上波形與音框的對照在圖 \ref{fig:enter-labelwav} 呈現。 該段語句內容為 "... what means could it..." ，上方兩個橫列為單詞標註、音位標註 \footnote{ARPABet 表示法，是以純字母表示的音位表示法。介紹音位分類的章節會對此詳細描述。音位中的數字表示重音。}。接下來四個橫列中，可以看見第三與第五個橫列將語句切割成以 20 毫秒為單位的片段，此即前面所述之音框。第三列為 HuBERT 模型分群數 100 所得之離散單元序列，而第五列則是由第二列的音位標註片段按照所對應的時間段，分別對齊到音框上的音素標註。由於音位的長度通常長於一個音框，因此在離散單元和音框音素標註在呈現上習慣將標註類別相同的音框合在一起成為長短不一但更接近時間發音的時間段，分別標在第四與第六列之上。
        \begin{figure}
            \centering
            \includegraphics[width=1\linewidth]{figures/praat.png}
            \caption{以音框對齊的離散單元與音素標註範例}
            \label{fig:enter-labelwav}
        \end{figure}
        %%%%%%%%%%%%%%%%%
        
        此時若將整個待分析資料集的語音訊號全部蒐集起來，一共有 $T'$ 個音框，如此可分別獲得一個離散單元序列 $\boldsymbol{z} = \{z_t\}_{t=1}^{T'}$ 與音素標註序列 $\boldsymbol{y} = \{y_t\}_{t=1}^{T'}$ 進行統計分析。我們可以根據離散單元與標註之間配對的出現次數，寫為一個雙變數的共同分佈（Joint Distribution）
\begin{align}
    p_{yz} = \frac{\sum^{T'}_{t=1}[{y_t = i \wedge z_t = j}]}{T'}
\end{align}

其中 $i$ 是第 $i$ 個音位類別，而 $j$ 指編號為 $j$ 的離散單元。兩個變數的邊際機率（Marginal Probability）分別為
\begin{align}
    p_z(j) & =\sum_i{p_{yz}(i, j)} \\
    p_y(i) & =\sum_j{p_{yz}(i, j)}
\end{align}
因此，對於每一個音位 $i$ 而言，這個音位最可能的對應離散單元為
\begin{align}
    z^\ast(i) = \arg\max_j p_{yz}(i, j)
\end{align}
與之相對應的，對於每一個離散單元的類別 $j$ 則可以找到機率最高的音位
\begin{align}
    y^\ast(j) = \arg\max_i p_{yz}(i,j)
\end{align}
透過這些定義，以下分節介紹將要用來分析的指標。

\subsection{純度}

　　本指標考慮音位和離散單元兩個序列之間對應的最高機率，因此從音位與離散單元的角度出發，可以得到以下兩項數據：

\paragraph{音位純度（Phoneme Purity）}\hfill \break
%
　　考慮每個離散單元對應的音位中，最高機率音位的機率，表示為
\begin{align}
    \mathbb{E}_{p_z(j)}\left[p_{y|z}(y^*(j)|j) \right]
\end{align}
此指標表示該單元是否對其對應的音位有足夠的代表性。

\paragraph{分群純度（Cluster Purity）}\hfill \break
%
　　與音位純度相對，改以每個音位的角度，考慮對應單元類別的機率
\begin{align}
    \mathbb{E}_{p_y(i)}\left[p_{z|y}(z^*(i)|i) \right]
\end{align}
        由於離散表徵進行分群演算法時的類別數是一項超參數（Hyperparameter），且通常離散單元的分群數量會比音位多，因此該統計數據本身不直接具有語音學的解釋意義，而且在分群數量很多時其數值會顯著下降。然而該指標在考量音位純度時必須一併考慮，因為當分群數非常多時，分群純度過低暗示離散單元做不到歸納音位類別的效果，使得音位純度失去其意義。一個極端的情形是每一個音框都給予不同的離散單元編號，如此音位純度可以達到100\%。

\subsection{熵和相互資訊}

　　除了純度提供「最高機率」的對應關係，根據 HuBERT 論文 \cite{hsu_hubert_2021-2} 中的分析方式，我們也可以從資訊理論的角度，觀察兩個序列的熵和相互資訊。

\paragraph{熵（Entropy）} \hfill \break
%
　　熵的定義按照資訊理論，衡量兩個序列中標籤類別出現機率的不確定性（Uncertainty），公式寫作：
\begin{align}
    H(y) & = \sum_i{p_y(i)\log p_y(i)} \\
    H(z) & = \sum_j{p_z(j)\log p_z(j)}
\end{align}
其中 $H(y)$ 和 $H(z)$ 分別為音位和離散單元的熵，數值愈高分別表示各種音位和離散單元出現的機率愈平均。

\paragraph{以音位標準化之相互資訊（Phone-normalized Mutual Information，PNMI）}\hfill \break
%
　　本數據以「觀察到某一個離散單元，能降低多少音位標註的不確定性」，定義該離散單元的出現背後提供了多少音位的資訊。公式寫為：
\begin{align}
    \frac{I(y;z)}{H(y)} & =\cfrac{\sum_i \sum_j p_{yz}(i, j) \log \cfrac{p_{yz}(i, j)}{p_y(i)p_z(j)}}{\sum_i p_y(i) \log p_y(i)} \\
                        & =\frac{H(y)-H(y|z)}{H(y)}                                                                              \\
                        & =1-\frac{H(y|z)}{H(y)}
\end{align}
        該項數據愈高，表示離散單元的分群愈能提供語音音位的資訊，是一個品質更好的分群結果。由於離散單元是否能夠正確對應到音位才是人們所關心的問題，因此與純度不同，只以音位的角度出發，而不考慮以離散單元分群的角度。

\section{語音學的音位分類（Phoneme Type）}

　　除了單一音位本身的特性以外，由於音位之間存在相似的特徵，可以分成幾個組別。這裡依照希氏（Sicherman） \cite{10097097}、阿氏（Abdullah）\cite{abdullah23_interspeech} 等前作的分組方式，對英語的音位進行分類。如此一來，除了單純把音位標註以約 40 類完全獨立的標籤看待，還能夠觀察這些離散單元是否有擷取到相似的發聲特徵。首先，按照發音過程氣流是否受到阻礙，因此可否形成獨立的音節，音位可以分為輔音與元音兩大類，而後再根據發音的細部特性共分成七組。

\paragraph{輔音（Consonant）} \hfill \break
　　
        輔音是指透過阻擋氣流發聲的音位，因此通常不單獨構成音節，
按照發音方式可分為以下五個類別：
        
        \begin{itemize}
            \item 塞音（Plosive）：以完全阻塞氣流的方式發音的音位，包含 /p/、/b/、/t/、/d/、/k/、/g/ 六種。
            \item 擦音（Fricative）：藉由在口腔中形成的縫隙，使氣流通過時摩擦形成的發音，包含 /f/、/v/、/s/、/z/、/\textesh/ (sh)、/\textyogh/ （如「garage」的 「-ge」）、/θ/ (無聲的 th)、/ð/ (有聲的 th)、/h/ 九種。
            \item 塞擦音（Affricate）：由塞音和同部位的擦音同時發出的輔音，英語中只有 /t\textesh/ 和 /d\textyogh/ 兩種，即 ch 和 j 的發音。
            \item 鼻音（Nasal）：使氣流通過鼻腔形成的聲音，有 /m/、/n/、/ŋ/ (ng) 三種。
            \item 近音（Approximant）：又稱半元音，為介於元音和輔音之間的聲音，有 /j/ (為 y 作為輔音時的發音)、/r/、/l/、/w/ 四種。
        \end{itemize}

\paragraph{元音（Vowel）} \hfill \break
　　
        與之相對，元音則是不阻礙氣流通過，因此可自成音節的音位。其中又可分為發音位置固定的單元音（Monophthong）和會移動發音位置的的雙元音（Diphthong）兩類。通常以 a、e、i、o、u 字母產生的聲音皆屬於此類別。
        
        透過將音位分成以上七組後，並重新分析統計指標，以觀察這些分組的規律如何在離散單元的出現機率上呈現，進而顯示離散單元是否與語音的發音方式具有一定的關聯性。

        另外，為了方便統計與作圖，這些音位在圖中並非以語言學慣用之國際音標（International Phonetic Alphabet，IPA）\cite{international1999handbook}，而是參考語音處理領域常用的「卡內基梅隆大學發音辭典（Carnegie Mellon University Pronouncing Dictionary，CMUDict）\cite{noauthor_cmu_nodate}」，取用其中的 ARPABet 表示法 \cite{klautau2001arpabet}，以避免字母以外的符號在處理上的困難。表 \ref{tab:ipa1}、\ref{tab:ipa2} 中列有更詳細的音位資訊\footnote{範例單詞取自 CMUDict 官網說明。}。

\input{tables/chapter3/ipatable}

\section{實驗集與分析模型}

　　本研究的分析對象參考無文字架構 \cite{noauthor_textless_2021, lakhotia_generative_2021, lakhotia_generative_2021-1} 的研究，
採用論文中提及的四種語音表徵，簡述如下：

\begin{itemize}
    \item HuBERT \cite{hsu_hubert_2021-2}：卷積式編碼器 + 轉換器預測器，以預測式學習訓練，其訓練目標為 K-平均分群演算法的結果，透過遮蔽語言模型的方式訓練。表徵來自轉換器第 6 層，每 20 毫秒作為一個音框
    \item CPC \cite{rivière2020unsupervised}：卷積式編碼器 + 遞迴式預測器，以對比式學習訓練。表徵來自預測器的中間層，每 10 毫秒提取一個向量表徵作為音框
    \item Wav2vec 2.0 \cite{baevski2020wav2vec}：卷積式編碼器 + 轉換器預測器，以對比式學習訓練。表徵來自轉換器第 14 層，每 20 毫秒作為一個音框
    \item LogMel：為 80 維對數梅爾時頻譜的聲學特徵，在此作為比較基線（Baseline）。音框寬度為 10 毫秒
\end{itemize}

        我們跟隨拉氏等人所提出的無文字架構 \cite{lakhotia_generative_2021-1} ，使用該篇論文中釋出之預訓練模型與 K-平均量化模型，預訓練模型的設定細節於原論文有更詳細的描述，而量化模型則是拉氏等人透過公開的 LibriSpeech 資料集 \cite{panayotov_librispeech_2015} 中之 train-clean-100 訓練子集，獲取語音表徵後執行 K-平均分群演算法所得，並釋出群數為 50、100 和 200 的三個版本。

        本論文以 LibriSpeech 之 train-clean-100 訓練子集作為分析對象，將語音語料庫的語音資料經過四個模型得到連續表徵後，再經過量化模型得到完全由離散單元組成的「虛擬文字」語料。至於音位標註的取得，則是透過強迫對齊器\footnote{https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner}的英語預訓練模型，將語料庫的文字轉寫轉換為帶有對應時間範圍的音位標註資料，並依據各自語音表徵的時間解析度，生成以音框對齊的音位標註語料，隨後進行相關性的分析。

}

　　 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%　　

\section{分析方式}

{
        % (1) 首先，先把純度的數據秀出來，然後秀四張表，說這是整體，然後再秀不同的分群數量。

　　針對模型得出之離散單元與音位標註之間的對應關係，為了更直觀的解釋這些指標的意義，並且看清楚這些數字背後之間代表的現象與細部特徵，我們將音位與離散單元的共同機率分佈 \(p_{yz}\) 用熱圖（Heatmap）呈現，來解釋這些指標的意義，並以此進一步往下深入探討。

        首先，這裡以 HuBERT 為基石模型、離散單元分群數為 50 的統計數據為例，圖 \ref{fig:hubert-50-joint-byprob} 說明我們如何分析語音離散表徵與音位標註的關係。
{


\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{figures/hubert-50-joint-byprob.png}
    \caption{HuBERT 模型、分群數為 50 之 \\
    離散單元與音位標註的共同機率分佈圖}
    \label{fig:hubert-50-joint-byprob}
\end{figure}

}
        圖中的縱軸表示各個音位，橫軸表示各個離散單元。在這張圖中，縱軸的音位是按照其邊際機率 \(p_y(i)\) 由高至低排序；橫軸的離散單元則是依據其對應的最高機率音位 \(y^\ast(j)\) 的縱軸排序位置進行排列。\footnote{如果兩個離散單元 \(j_1\) 和 \(j_2\) 對應到相同的音位 \(y^\ast = y^\ast(j_1) = y^\ast(j_2)\)，則依照機率值 \(p_{yz}(y^\ast, j_1)\) 和 \(p_{yz}(y^\ast, j_2)\) 由高到低進行排序，對於多個離散單元的情況以此類推。} 這樣可以在熱圖上呈現出由左上至右下的對應關係。


        為了評估離散表徵是否有捕捉到與音位相關的資訊，我們可以分別從音位與離散單元的兩個角度出發，考慮以下兩個問題：
\begin{enumerate}
    \item 一個離散單元所對應的音位的集中或分散程度如何？如果一個音框的語音訊號被模型指示為特定的離散單元，該單元作為虛擬標註，能多大程度的對應到人耳感知的音位標註？也就是這些虛擬標註，是否達成音位標註類似的效果，足以把不同語音特徵區分開來。
    \item 反之，對於每個音位而言，它們所對應的離散單元集中程度如何？從這個角度出發，可以觀察不同音位的集中程度，進而推論模型是否能夠辨認出該音位的發音特性，藉由給予夠高的一致性將這些語音訊號分類在一起。會不會有某一些音位很難被歸類出來？
\end{enumerate}

{

        就綜觀的角度，這兩個問題的答案可以分別很直觀的從圖中顏色的深淺觀察出來，也正好對應前面所提及的兩個純度指標：
        \begin{enumerate}
            \item 將每個直行（Column）取最大值相加後的總和即為音位純度
            \item 將每個橫列（Row）取最大值相加後的總和則是分群純度
        \end{enumerate}

        從這裡我們可以看到，當分群數量增加時，音位純度可以在每個直行上取到更多的機率值，這也意味著當分群數量與音框數量相同時，音位純度可以達到 100\%，與前面的描述互相吻合。另一方面，當分群數量增加時，每個格子的機率值會因為離散單位數量的增多而被稀釋，而分群純度受到音位數量限制，只能取 41 個 $p_{yz}$ 值的總和，使得單位純度因而明顯降低。

}


%%% 先放結果



(((這些是純度跟 MI 的 table，可以直接看一下，對照熱圖觀察)))


\subsection{綜觀不同語音離散表徵的比較}

{


\begin{table}[!htbp]
    \centering
    \begin{subtable}[t]{\textwidth}
        \centering
        \begin{tabular}{|c|c|c|c|c|c|} \hline
                        & 音位純度   & 分群純度   & 音位熵    & 離散單元熵  & PNMI   \\ \hline
            HuBERT      &     0.5256 &     0.3382 &    3.3152 &      3.8681 & 0.4993 \\ \hline    %% 1.6552 h
            CPC         &     0.5188 &     0.3812 &    3.3146 &      3.7918 & 0.4992 \\ \hline    %% 1.6545 c
            Wav2vec 2.0 &     0.4006 &     0.2676 &    3.3152 &      3.8215 & 0.3706 \\ \hline    %% 1.2286 w
            LogMel      &     0.3253 &     0.1473 &    3.3158 &      3.8630 & 0.2647 \\ \hline    %% 0.8776 l 
        \end{tabular}
        \caption{群數 = 50}
        \label{tab:ch3-clu050-phn}
    \end{subtable}

    \vspace{0.5cm}

    \begin{subtable}[t]{\textwidth}
        \centering
        \begin{tabular}{|c|c|c|c|c|c|} \hline
                        & 音位純度   & 分群純度   & 音位熵    & 離散單元熵  & PNMI   \\ \hline
            HuBERT      &     0.6097 &     0.2553 &    3.3152 &      4.5704 & 0.5786 \\ \hline    %% 1.9181 h
            CPC         &     0.5895 &     0.2674 &    3.3146 &      4.5034 & 0.5557 \\ \hline    %% 1.8418 c
            Wav2vec 2.0 &     0.4877 &     0.2118 &    3.3152 &      4.5284 & 0.4596 \\ \hline    %% 1.5235 w
            LogMel      &     0.3348 &     0.0931 &    3.3158 &      4.5591 & 0.2789 \\ \hline    %% 0.9247 l 
        \end{tabular}
        \caption{群數 = 100}
        \label{tab:ch3-clu100-phn}
    \end{subtable}

    \vspace{0.5cm}

    \begin{subtable}[t]{\textwidth}
        \centering
        \begin{tabular}{|c|c|c|c|c|c|} \hline
                        & 音位純度   & 分群純度   & 音位熵    & 離散單元熵  & PNMI   \\ \hline
            HuBERT      &     0.6474 &     0.1644 &    3.3152 &      5.2681 & 0.6289 \\ \hline    %% 2.0849 h
            CPC         &     0.6098 &     0.1789 &    3.3146 &      5.1885 & 0.5882 \\ \hline    %% 1.9497 c
            Wav2vec 2.0 &     0.5427 &     0.1467 &    3.3152 &      5.2173 & 0.5188 \\ \hline    %% 1.7199 w
            LogMel      &     0.3474 &     0.0569 &    3.3158 &      5.2322 & 0.2955 \\ \hline    %% 0.9798 l 
        \end{tabular}
        \caption{群數 = 200}
        \label{tab:ch3-clu200-phn}
    \end{subtable}

    \caption{不同群數在四種基石模型的音位分析數據}
    \label{tab:single-cluster-results}
\end{table}

}

{

% \newcommand{\jeffheightt}[1]{\includegraphics[width=0.6\linewidth]{#1}}
\newcommand{\jeffheightt}[1]{\includegraphics[width=1\linewidth]{#1}}

\begin{figure}
     \centering
     \begin{subfigure}{\textwidth}  % [t]{\textwidth}
         \centering
         \jeffheightt{figures/hubert-50-joint-byprob--new1.png}
         \caption{HuBERT}
         \label{fig:ch3-heatmap-model--hubert-50-joint-byprob}
     \end{subfigure}
     \vfill

     \begin{subfigure}{\textwidth}  % [t]{\textwidth}
         \centering
         \jeffheightt{figures/cpc-50-joint-byprob.png}
         \caption{CPC}
         \label{fig:ch3-heatmap-model--cpc-50-joint-byprob}
     \end{subfigure}

     % \vfill
     % \begin{subfigure}{\textwidth}  % [t]{\textwidth}
     %     \centering
     %     \jeffheightt{figures/cpc-50-joint-byprob.png}
     %     \caption{CPC}
     %     \label{fig:ch3-heatmap-model--cpc-50-joint-byprob}
     % \end{subfigure}
     % \vfill
     % \begin{subfigure}{\textwidth}  % [t]{\textwidth}
     %     \centering
     %     \jeffheightt{figures/logmel-50-joint-byprob.png}
     %     \caption{LogMel}
     %     \label{fig:ch3-heatmap-model--logmel-50-joint-byprob}
     % \end{subfigure}
     \caption{模型比較}
     \label{fig:ch3-heatmap-model-comparison--part1}
\end{figure}


\begin{figure}
    \ContinuedFloat
    % \setcounter{subfigure}{2}
     \centering
     % \begin{subfigure}{\textwidth}  % [t]{\textwidth}
     %     \centering
     %     \jeffheightt{figures/hubert-50-joint-byprob--new1.png}
     %     \caption{HuBERT}
     %     \label{fig:ch3-heatmap-model--hubert-50-joint-byprob}
     % \end{subfigure}
     % \vfill
     % \begin{subfigure}{\textwidth}  % [t]{\textwidth}
     %     \centering
     %     \jeffheightt{figures/w2v2-50-joint-byprob.png}
     %     \caption{Wav2vec 2.0}
     %     \label{fig:ch3-heatmap-model--w2v2-50-joint-byprob}
     % \end{subfigure}
     % \vfill
     
          \begin{subfigure}{\textwidth}  % [t]{\textwidth}
         \centering
         \jeffheightt{figures/w2v2-50-joint-byprob.png}
         \caption{Wav2vec 2.0}
         \label{fig:ch3-heatmap-model--w2v2-50-joint-byprob}
     \end{subfigure}
     
     \vfill
     \begin{subfigure}{\textwidth}  % [t]{\textwidth}
         \centering
         \jeffheightt{figures/logmel-50-joint-byprob.png}
         \caption{LogMel}
         \label{fig:ch3-heatmap-model--logmel-50-joint-byprob}
     \end{subfigure}
     \caption{模型比較（續）}
     \label{fig:ch3-heatmap-model-comparison--part2}
\end{figure}

}


　　首先，表 \ref{tab:single-cluster-results} 比較了不同模型的純度與相互資訊的數據，而這四個離散表徵在分群數為 50 的機率聯合分佈圖於圖 \ref{fig:ch3-heatmap-model-comparison--part1} 中呈現。從這些分析結果，我們可以觀察到 HuBERT 和 CPC 對於捕捉音位之間的關係是比較好的，音位純度與分群純度都較高這點，也在熱圖上以較為清晰深色的格子呈現。由此可以說明 HuBERT 和 CPC 模型在捕捉訊號中的發音特徵能力效果較 Wav2vec 2.0 和聲學特徵的 LogMel 好上不少。同樣的趨勢在群數為 100 和 200 時也能被觀察出來，尤其又以 HuBERT 效果明顯好上不少。

        除了從熱圖與純度觀察，我們也可以觀察每個模型對應離散單元所對應的音位的條件音位熵分佈，來探討這些離散單元捕捉音位分佈的效果。圖 \ref{fig:zhifangtu} 展示了四種模型的音位熵分佈直方圖，比較四個模型在群數 50 和 100 的直方圖，我們也可以得到和前段相同的結論 --- HuBERT 的表現是四個模型中最好的。

        因此，我們可以著重觀察 HuBERT，進一步比較三個不同分群數的機率熱圖。依循前作慣例 \cite{wells_phonetic_2022, zhang2024speechtokenizer, liu2024dinosr} ，我們在這邊以條件機率呈現。從圖中可以發現，當分群數量上升時，離散單元之間有對區分不同音位的效果得到提升。


%%%%%%%%%%%% ///////////

        以上是綜觀整個系統給予虛擬標註時，對應到音位標註的好壞。然而我們可以更進一步的探討各音位與離散單元之間的內部差異，也就是分別探討：
\begin{itemize}
    \item 哪些離散單元比較能集中抓取音位的特徵，不會與其他音位混淆？
    \item 如果一個離散單元被分散的對應到多個音位，那麼這些音位可能是哪幾個？是否存在某些共同特徵？
\end{itemize}

((( 於是，接下來我們便分別以離散單元與音位各自的角度分別探討這張分佈圖的細節，可以帶給我們什麼細部資訊，最後再回頭對照這些觀察是否可以在整體熱圖上有所對應的規律被呈現出來。 )))

        說明完以上指標後，我們將展示不同離散表徵模型的所有分析，彼此先進行綜觀比較，此後再針對細部的特徵分析。

%%% (where the table?)))))
%%% 先看縱軸


{
        % (2) 然後接下來從縱軸看基於離散單元的特性，那你可以看的有，第一個它們的直方圖，看這些離散單元彼此之間亂不亂，然後你可以看說每個離散單元，它的對應的音位排名是不是同一類，同一類那你可以把那個顏色圖拿出來，然後你顏色圖拿出來之後為了刻劃這件事情，你就可以去用類別標註這個數據來講述這件事。

        這邊就舉說一個模型有，另一個模型也有，就夠了。
}


\subsection{看離散單元}

        由於這些問題是以離散單元的角度出發，因此我們仿照前作如 SpeechTokenizer \cite{zhang2024speechtokenizer}、DinoSR \cite{liu2024dinosr} 的作法，將熱圖改以 $p_{y|z}(i|j)$ 呈現，即對每個直行進行標準化得到條件機率，以顯示每個單位對應到哪個音位，探討這種對應如何集中或分散。

%%%%%%%%%%%%%%%%5/////////////////////=============


{
\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{figures/0000000.png}
    \caption{這邊之後放直方圖}
    \label{fig:zhifangtu}
\end{figure}

  }
  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

        接下來，我們切入去觀察模型細部的個案探討。首先，我們先從離散單元的角度切入，我們可以發現，如同前面的直方圖所說，這些離散單元本身在編碼對應的音位本身的均勻程度並不是那麼一致。然而即便如此，從圖上那些不在線上的點，我們想知道的是，除了第一名的音位之外，第二名以後的音位會不會其實跟第一名之間也有一定的相關性。

        因此，我們可以把各個離散單元之間機率最高的五個對應音位按照語音學分組的順序依序排列出來，如圖 \ref{fig:enter-labfffel} 所示。可以看到後面幾名的音位確實都跟第一個都有很高的相關性。\jeffcomment{（是不是又要重講一遍前面的了？拉過來？）}

\jeffcomment{前面的細部非線的黑點點先拿掉}

        %%%%%%%%%%%%%%%%5/////////////////////
\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{figures/11111111.png}
    \caption{HuBERT 模型、分群數為 50 之\\
$p_{y|z}(i|j)$  條件機率分佈圖}
    \label{fig:hubert-50-givenunit-byprob}
\end{figure}
        從圖 \ref{fig:hubert-50-givenunit-byprob} 中可以更明顯的看出，模型會耗費不少種類的離散單元於編碼非音位的音素標註（尤其是 sil）之上。\jeffcomment{加上 silence ratio?}此外，每個離散單元對於其對應的訊號所對應的音位集中程度有高有低，使得音位純度無法到達 1.00。然而，這邊比較有趣的點是，觀察那些對應音位比較分散的離散單元，我們其實可以發現這些音位彼此之間有很強的關聯性，幾乎與前述的語音分類一致。  % 

        \begin{figure}
            \centering
            \includegraphics[width=1\linewidth]{figures/unit_rank_phn.png}  % figures/unit_perspective.png
            \caption[]{
離散單元對應的前幾高音位示意
% 。圖中的方框、圓圈等形狀
}
                                          % 表示輔音發聲部位，外框顏色則表示清濁音。注意元音都屬於濁音
            \label{fig:unit-to-phn-rankings}
        \end{figure}
        
        這件事可以從熱圖上由左上而右下連線中，不在線上但顏色較深的區塊中觀察出來。但由於直接從熱圖上觀察比較難以呈現，因此我們另外統計出表 \ref{fig:unit-to-phn-rankings}，其中展現的是幾個離散單元對應的前五高機率音位，並且用顏色標明各音位所屬的語音學類別。從表中大致可以看出以上描述的趨勢，而且即便不是同一個語音學類別，按照前面講解語音學對音位歸類的另外兩個層面 --- 發音部位和清濁音，還是可以將各離散單元的前幾名之中盡量找出共通點。例如 05 號單元對應的前兩名 /t/ 和 /s/ 雖然並不屬於同一個發聲方式，因而被分成兩個類別，但如果從國際音標表中的「發音部位」來觀察，會發現它們都屬於「齒音」。換言之這些離散單元捕捉到的語音特性是多個面向的，並不僅限於單一的分類方式，而是可以對應到國際音標表上至少兩個維度以上的類型。

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{figures/ipa_similarity.png}
    \caption[]{
國際音標表的輔音表格，說明離散單元}
                                                                對語音聲學特徵的捕捉並不僅限單一面向
    \label{fig:ipa-cons-table-sim}
\end{figure}

        透過以上的觀察，因此我們有足夠的理由重新對熱圖的縱軸重新排列，並按照語音學分類進行分組，來觀察這些離散單元是如何指示出音位之間的相似性，區分出同個音位、同類發音，或者如何被混淆為其他類別，而這些類別是否有某些特徵，最後這樣的現象是否只在單一模型出現，抑或是在不同的離散單元系統都會發生。

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{figures/hubert-50-givenunit-byphn.png}
    \caption[]{% \medskip % \small
        HuBERT 模型、分群數為 50 之離散單元}
                                                    與音位標註的條件機率，依照語音學分類排序的分佈圖
    \label{fig:hubert-50-givenunit-byphn}
\end{figure}

        這張圖的分組順序是依照韋氏（Wells） \cite{wells_phonetic_2022} 論文中的出現順序排列，而組別內則是清音在上、濁音在下，而同樣清濁音則是以發音位置由前往後排列。除了縱軸上按照音位本身特性分組，依循純度中使用的「代表音位」 $i^\ast$ 概念，我們同樣也對每個離散單元的代表音位排序，並且也依照這些代表音位進行分組觀察。



\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{figures/fff.png}
    \caption{Enter Caption}
    \label{fig:enter-labfffel}
\end{figure}

        因此，為了刻劃出這種離散表徵歸類到同樣語音學分類之比例的程度，我們可以改統計把所有音素標註改用語音學分類取代，再次計算純度的數據來確認這件事。圖 \ref{ffffff} 就說明了，HuBERT 不但能夠很好的區分出音位，即便是沒有分到準確的音位，也可以擷取到最相近類別的音位，因此在語音學類別的純度上會比其他模型來得高。

        
        為了比較好的刻劃這個在分群內的好壞，我們接下來多算兩個指標：\par
\begin{enumerate}
    \item 語音分類的純度：為了確認每個離散單元如何「將音位至少分到同一語音學類別」的程度，藉由將前面音位純度的式子，但將音位標註改為語音學類別，便可以求得這個數據。
\end{enumerate}



\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{figures/ffff.png}
    \caption{fffff}
    \label{ffffff}
\end{figure}

}

\subsection{看音位}

{
        % (3) 然後再來換橫軸，看每一個音位對應的離散單元熵值，來決定說哪些音位比較好哪些比較難，那這件事情是不是也可以擴及到其它的模型。
}



% /////////

        最後，我們來從橫軸音位的角度切入，觀察哪些音位可能是比較集中或分散，也就是容易或難以被離散單元編碼的。表  \ref{fig:entefffffr-label} 與表 \ref{ewfeef} 呈現了分群數為 50 和 100 中，離散單元熵最高與最低的幾個音位，由此可以看到：spn、AH、IH、T、D 等音位是比較難以被捉摸的音位，而 AA、EY、F、ZH、SH、S 等是比較容易被抓取的音位。整體而言，塞音都屬於熵比較高的，而擦音則是比較集中，而且這個趨勢大致上不同的模型、分群數都存在，只是又以 HuBERT 相對最明顯。

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{figures/aaaaaaaaaaaaaa.png}
    \caption{Enter Caption}
    \label{fig:entefffffr-label}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{figures/asdfasdfsfasfaew.png}
    \caption{wsfe}
    \label{ewfeef}
\end{figure}

\subsection{考慮分組指標}


{
        % (4) 然後最後就是你要看，就是分不同群因為你已經有標註了，那我們也可以藉由這個類別分不同群之間，它的純度，一來你可以看針對每一個語音學類別，它模型的表現是否一致，然後你還可以比較不同的語音學類別彼此之間，八個類別的差異，而第八個類別它很特別，因為它不是音位，那你可以去計算說，它的佔用的比例有多少這件事情。
}



        為了比較好的刻劃這個在分群內的好壞，我們接下來多算兩個指標：\par
\begin{enumerate}
    \item 各發音類別的純度：為了衡量模型對於每個類別內部區分不同音位的能力，比較模型對於不同組別區分音位的難易度，我們可以根據音位的語音學類別，將所有的音框等效分成八份語料後，分別再次統計純度（亦即計算對語音學類別取條件機率後計算純度）。
\end{enumerate}


% /////////
% /////////
% /////////


        另外，既然已經可以根據語音學類別對機率熱圖進行分群，我們便可以將資料集按照語音學類別分組， 然後去探討各自類別的純度高低。 （細緻說明一下？） 如此一方面可以觀察模型之間的差異，也可以觀察不同語音學類別之間發音特徵擷取的難易程度。因此，表 \ref{sdfsdf} 中變呈現了這些模型的比較數據。

 \begin{figure}
     \centering
     \includegraphics[width=0.5\linewidth]{figures/lll.png}
     \caption{sldflsdlf}
     \label{sdfsdf}
 \end{figure}

        首先，由圖中依然可以觀察到 HuBERT 優於其他模型，以及分群數愈多相互資訊與音位純度愈高等和前述一致的趨勢。此外，我們還可以觀察到，撇去非音位（表格中的「XXX」）這類由於只有 sil 一類標註，因此相互資訊和純度相當高之外，就近音、雙元音和擦音是純度相對高的，而塞音、塞擦音則是比較難以被抓取的語音學組別。最後，關於非音位的語音訊號，觀察這些模型的等效花費多少比例的離散單元去代表這些非音位的資訊，可以發現 HuBERT 雖然擷取音位的整體表現比較好，但也耗費了不低比例的單元去編碼非音位的資訊。


{
        % (5) 最後最後可把整張圖，把前面得到那些 HuBERT 比較好的結論塞音比較難編碼的結論用熱圖的深淺來確認。
}


\subsection{最後整體確認}

% ////

        在那之後的最後，仿照韋氏（Well） \cite{wells_phonetic_2022} 的研究方法，我們可以觀察可能哪些離散單元對音位以及其分組具有代表性。然而比起直接看離散單元的編號，在此我們改由對機率熱圖做分區的細部視覺化剖析，來最後確認前面的那些觀察。在此由於 HuBERT 表現最好，而 100 這個不會太細但又足以區分出塞擦音的分群數，來進行細部剖析。

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{figures/sdfasdfasdfaqqqqqqqq.png}
    \caption{Enter Caption}
    \label{sdfasdfasdfaqqqqqqqq}
\end{figure}

        從圖 \ref{sdfasdfasdfaqqqqqqqq} 可以看出，塞音和塞擦音的色塊確實比較淺，也就是比較分散，而擦音和雙元音則是很明顯的深色色塊，代表分群比較集中，由此應證前面從音位的離散單元熵以及各語音學分類的純度等觀察。\jeffcomment{（切塊出來看）}


　　 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%　　


{

\section{本章總結}


　　在這裡，我們從純度的計算開始，對於整個機率熱圖做了視覺化分析，並且藉由語音學提供的分群方式，將原先約 50 類獨立標籤透過語音知識的協助，進行更深入的特性分析探討，也確認了 HuBERT 之所以優於其他模型，並常被無文字架構所使用，從語音音位特性的擷取的優秀表現中得到了不錯的印證。

%%%%%%%%=============================


　　本章節探討以音框為單位取出的語音離散表徵與對應的音位標註之間的關係，從分析結果中可以看到，HuBERT 模型的離散表徵確實與人類理解的語音單位「音位」之間具有最明顯的相似性，也進一步證明為何 HuBERT 是抽取語音離散表徵時最常使用的模型。

        然而，單一離散表徵僅能代表 10 或 20 毫秒的語音訊號，而音位的長度經常佔據不只一個離散表徵。因此，下一章節將進一步組合多個離散表徵成為符記，分析它們與音位之間的關係。

% 　　從統計數據出發，我們針對聯合分佈的各個面向，配合了語音學知識的分類進行了細部探討，發現了 hunert 模型怎樣怎樣，而這件事可能在其他的模型之中差不多是 holid 住的。然後，因為 hunert 本身捕捉的各項純度與 MI 明顯較高，以此可以驗證為什麼 HuBERT 的離散單元可以在無文字架構內被當成類似音位或文字的表徵，並進而套用於語音語言模型的訓練上，同時為許多做語音模型解釋性的作品所關注citehao。


}

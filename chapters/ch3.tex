\chapter{單一語音離散表徵與音位的關係} \input{chapters/cych3}

\section{分析結果}

\subsection{不同語音離散表徵的比較}

　　首先是比較不同模型的離散特徵之數據與機率分佈圖：

純度：
{

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{figures/000.png}
    \caption{比較表}
    \label{fig:enter-label}
\end{figure}

}
機率分佈圖：
{

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{figures/hubert50.png}
    \caption{Hubert}
    \label{fig:enter-label}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{figures/w2v250.png}
    \caption{w2v2}
    \label{fig:enter-label}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{figures/cpc50.png}
    \caption{cpc}
    \label{fig:enter-label}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{figures/logmel50.png}
    \caption{logmel}
    \label{fig:enter-label}
\end{figure}

}

        比較不同的模型的聯合分佈後，我們可以觀察到這些模型之間，確實存在。

        就是說標注跟單元之間的 相關性 高低，比較，從聯合分佈圖上也可以明顯的呈現出來，進而說明這些不同的語音離散表徵之前，捕捉訊號中的發音特徵能力的強弱。從圖中可以看出，HuBERT 跟 CPC 的效果比另外兩種表徵好上不少。

        此外，我們也可以比較同一種語音表徵之下，不同的離散單元分群數之間對於音位特徵捕捉的強弱程度。基於前面表徵純度與相互資訊的考量，這邊固定用 HuBERT 當比較對象。從這三種分群數看來，離散單元數量愈多，愈能夠區分出比較細節的語音類別。例如，如果要從每個 離散單元 的代表音位來觀察，要至少有 100 個群數，才至少有一個離散單元能代表塞擦音。如果分群數量太少，很多細節的發音音位則很容易被放在一起，難以區別出更細節的發音差異。

        再者，我們觀察到模型會消耗一定比例的離散單元去代表非音位的發音，以此我們計算出一個「非音位比例」，也就是等效有幾個 離散單元 被拿去代表這些不是音位的聲音。具體算法是使用 $E [ u | p ] $  總和除以離散單元的數量。

        然後，我們期望看到一個單元系統怎麼有效的去使用這些離散單元，因此我們可以畫一張離散單元音位熵的直方圖（Histogram）來刻劃模型系統在使用這些離散單元的集中程度。如果整體向熵值低處偏，表示模型的各種離散單元所代表的音位都是相對確定的，也就是更好的捕捉到了音位特徵。

        最後，為了觀察各自不同語音學類別內分群的好壞，我們可以算語音學類別的純度，並且再以各個語音學類別區分出來，計算八個類別的各自 條件機率下計算的 純度，以此比較不同表徵、分群數在針對不同語音學類別的特徵補綴效果。

        比較完這些表徵與離散單元數量的各項綜觀統計指標後，我們基於 相互資訊 和 純度 的高低，著重關注於 HuBERT 100 和 50 模型或 CPC，藉由觀察和比較兩個模型共有的規律，往下細部探討該模型所捕捉到的離散單元和音位之間的關係。

\subsection{個案探討}  % 分組討論  %

　　首先，承接前面所述的「熱圖上不在斜線上的點」，我們可以觀察每個離散單元所對應的 音位 之間的共同特性。

        接著，我們確認一下對應最紛亂與最集中的幾個 離散單元 的狀況。

        接著，跟隨韋氏（Wells）\cite{wells_phonetic_2022} 之前的作法，我們觀察各類別的 音位 可能各自是以那些離散單元為代表。

        之後，從各個 音位 的熵值來觀察，我們可以發現\textcolor{red}{某某某某某}幾個音位的熵值特高特低，來發現這些音位可能是比較難以捕捉的。而這個現象在 50 模型又可能是怎樣怎樣的。

\subsubsection{切塊出來}

　　最後，基於我們已經有對語音學分類，我們可以觀察熱圖上不同語音學類別所切出來的區域的亂度，來觀察各類別的發音特徵捕捉的難易度。例如塞音怎樣怎樣啊……

{


\section{本章總結}

　　本章節探討以音框為單位取出的語音離散表徵與對應的音位標註之間的關係，從分析結果中可以看到，HuBERT 模型的離散表徵確實與人類理解的語音單位「音位」之間具有最明顯的相似性，也進一步證明為何 HuBERT 是抽取語音離散表徵時最常使用的模型。

        然而，單一離散表徵僅能代表 10 或 20 毫秒的語音訊號，而音位的長度經常佔據不只一個離散表徵。因此，下一章節將進一步組合多個離散表徵成為符記，分析它們與音位之間的關係。

% 　　從統計數據出發，我們針對聯合分佈的各個面向，配合了語音學知識的分類進行了細部探討，發現了 hunert 模型怎樣怎樣，而這件事可能在其他的模型之中差不多是 holid 住的。然後，因為 hunert 本身捕捉的各項純度與 MI 明顯較高，以此可以驗證為什麼 HuBERT 的離散單元可以在無文字架構內被當成類似音位或文字的表徵，並進而套用於語音語言模型的訓練上，同時為許多做語音模型解釋性的作品所關注citehao。


}
